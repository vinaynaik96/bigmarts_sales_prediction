{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8c1083",
   "metadata": {},
   "source": [
    "# All ML Pipeline Combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "edfdd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717964e",
   "metadata": {},
   "source": [
    "# 1 : Exploratary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4098f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split data train and test\n",
    "train = pd.read_csv(\"data/train_v9rqX0R.csv\")\n",
    "test = pd.read_csv(\"data/test_AbJTz2l.csv\")\n",
    "output_file = 'ABB_submission.csv'\n",
    "\n",
    "# 2. Combine train and test for consistent preprocessing\n",
    "test['Item_Outlet_Sales'] = np.nan\n",
    "data = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7781a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Standardize Item_Fat_Content\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({\n",
    "    'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg': 'Regular'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f7d7edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create Item_Type_Combined\n",
    "data['Item_Type_Combined'] = data['Item_Identifier'].apply(lambda x: {'F': 'Food', 'D': 'Drinks', 'N': 'Non-Consumable'}.get(x[0], 'Other'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708efc7",
   "metadata": {},
   "source": [
    "# 2 : Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39287f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Non consumables lets make it non edible\n",
    "data.loc[data['Item_Type_Combined'] == 'Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b3676b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Impute Item_Weight with group mean\n",
    "data['Item_Weight'] = data['Item_Weight'].fillna(\n",
    "                      data.groupby('Item_Type_Combined')['Item_Weight'].transform('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f32a3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Flag zero visibility and replace with NaN and impute\n",
    "data['Zero_Visibility_Flag'] = (data['Item_Visibility'] == 0).astype(int)\n",
    "data['Item_Visibility'] = data['Item_Visibility'].replace(0, np.nan)\n",
    "data['Item_Visibility'] = data['Item_Visibility'].fillna(\n",
    "    data.groupby(['Item_Type_Combined', 'Outlet_Type'])['Item_Visibility'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fef0532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Impute Outlet_Size\n",
    "def fill_outlet_size(row):\n",
    "    mode = data[(data['Outlet_Type'] == row['Outlet_Type']) & \n",
    "                (data['Outlet_Location_Type'] == row['Outlet_Location_Type'])]['Outlet_Size'].mode()\n",
    "    return mode.iloc[0] if not mode.empty else 'Medium'\n",
    "data['Outlet_Size'] = data.apply(lambda row: fill_outlet_size(row) if pd.isna(row['Outlet_Size']) else row['Outlet_Size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82fa32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Outlet years feature\n",
    "data['Outlet_Years'] = 2013 - data['Outlet_Establishment_Year']\n",
    "\n",
    "# 10. Log transform features\n",
    "data['Item_MRP_log'] = np.log1p(data['Item_MRP'])\n",
    "data['Item_Visibility_log'] = np.log1p(data['Item_Visibility'])\n",
    "\n",
    "# 11. Mean visibility ratio\n",
    "data['Item_Visibility_MeanRatio'] = data['Item_Visibility'] / (\n",
    "    data.groupby(['Item_Identifier', 'Outlet_Type'])['Item_Visibility'].transform('mean') + 1e-8\n",
    ")\n",
    "\n",
    "# 12. Interaction features\n",
    "data['MRP_Outlet_Years'] = data['Item_MRP'] * data['Outlet_Years']\n",
    "data['MRP_Visibility'] = data['Item_MRP'] * data['Item_Visibility']\n",
    "data['MRP_Weight'] = data['Item_MRP'] * data['Item_Weight']\n",
    "\n",
    "# 13. Category features\n",
    "data['Item_Category'] = data['Item_Identifier'].str[:2]\n",
    "train_mask = ~data['Item_Outlet_Sales'].isna()\n",
    "overall_mean = data[train_mask]['Item_Outlet_Sales'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43b19a",
   "metadata": {},
   "source": [
    "# 3 : Encoding Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51c826a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Target encoding\n",
    "category_stats = data[train_mask].groupby('Item_Category')['Item_Outlet_Sales'].agg(['mean', 'count'])\n",
    "category_stats['smoothed'] = (category_stats['count'] * category_stats['mean'] + 10 * overall_mean) / (category_stats['count'] + 10)\n",
    "data['Item_Category_TargetEncoded'] = data['Item_Category'].map(category_stats['smoothed']).fillna(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0697378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Ordinal encoding\n",
    "sorted_means = category_stats['mean'].sort_values()\n",
    "category_to_ordinal = {cat: idx for idx, cat in enumerate(sorted_means.index)}\n",
    "data['Item_Category_Ordinal'] = data['Item_Category'].map(category_to_ordinal).fillna(len(category_to_ordinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18a64b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Mean sales encoding\n",
    "data['Type_Combined_MeanSales'] = data['Item_Type_Combined'].map(data[train_mask].groupby('Item_Type_Combined')['Item_Outlet_Sales'].mean())\n",
    "data['Outlet_MeanSales'] = data['Outlet_Identifier'].map(data[train_mask].groupby('Outlet_Identifier')['Item_Outlet_Sales'].mean())\n",
    "data['Category_MeanSales'] = data['Item_Category'].map(data[train_mask].groupby('Item_Category')['Item_Outlet_Sales'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4c60a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Label encode remaining categorical features\n",
    "le_cols = ['Item_Fat_Content', 'Outlet_Location_Type', 'Outlet_Size', 'Outlet_Type', 'Item_Type_Combined', 'Outlet_Identifier']\n",
    "for col in le_cols:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f3a4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Spliting train and test data from data to original form\n",
    "train_clean = data[~data['Item_Outlet_Sales'].isna()].copy()\n",
    "test_clean = data[data['Item_Outlet_Sales'].isna()].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a0c86",
   "metadata": {},
   "source": [
    "# 4 : Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9d827c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Final feature list after removing less relevant feature and non important feature\n",
    "features = [\n",
    "    'Item_Weight', 'Item_Visibility', 'Item_Fat_Content', 'Item_Type_Combined',\n",
    "    'Item_MRP', 'Outlet_Identifier', 'Outlet_Size',\n",
    "    'Outlet_Location_Type', 'Outlet_Type', 'Outlet_Years',\n",
    "    'Item_Visibility_MeanRatio', 'Zero_Visibility_Flag',\n",
    "    'Item_MRP_log', 'Item_Visibility_log',\n",
    "    'MRP_Outlet_Years', 'MRP_Visibility', 'MRP_Weight',\n",
    "    'Type_Combined_MeanSales', 'Outlet_MeanSales', 'Category_MeanSales',\n",
    "    'Item_Category_TargetEncoded', 'Item_Category_Ordinal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002bd98",
   "metadata": {},
   "source": [
    "# 5 : Data Imputation and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3e6b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Imputation using KNN\n",
    "\n",
    "X = train_clean[features]\n",
    "y = train_clean['Item_Outlet_Sales']\n",
    "X_test = test_clean[features]\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5438891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Scaling data using Min Max scalaer\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b721e4",
   "metadata": {},
   "source": [
    "# 6 : Spliting based on training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c217667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 22. Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962145ab",
   "metadata": {},
   "source": [
    "# 7 . ML Modelling with different regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f2b330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 1065.44\n"
     ]
    }
   ],
   "source": [
    "# 23. Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_preds = lr.predict(X_val)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_val, lr_preds))\n",
    "print(f'Linear Regression RMSE: {lr_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77d6ab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression RMSE: 1064.84\n"
     ]
    }
   ],
   "source": [
    "# 24. Ridge Regression\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_preds = ridge.predict(X_val)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_val, ridge_preds))\n",
    "print(f'Ridge Regression RMSE: {ridge_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b72e46e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression RMSE: 1063.91\n"
     ]
    }
   ],
   "source": [
    "# 25. Lasso Regression\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_preds = lasso.predict(X_val)\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_val, lasso_preds))\n",
    "print(f'Lasso Regression RMSE: {lasso_rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "25613f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet RMSE: 1441.71\n"
     ]
    }
   ],
   "source": [
    "# 26. ElasticNet\n",
    "enet = ElasticNet()\n",
    "enet.fit(X_train, y_train)\n",
    "enet_preds = enet.predict(X_val)\n",
    "enet_rmse = np.sqrt(mean_squared_error(y_val, enet_preds))\n",
    "print(f'ElasticNet RMSE: {enet_rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cdd33bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 1501.42\n"
     ]
    }
   ],
   "source": [
    "# 27. Decision Tree\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_preds = dt.predict(X_val)\n",
    "dt_rmse = np.sqrt(mean_squared_error(y_val, dt_preds))\n",
    "print(f'Decision Tree RMSE: {dt_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "14e78514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF RMSE: 1063.89\n"
     ]
    }
   ],
   "source": [
    "# 28. Train & validate baseline RandomForest\n",
    "rf_base = RandomForestRegressor(random_state=42)\n",
    "rf_base.fit(X_train, y_train)\n",
    "base_preds = rf_base.predict(X_val)\n",
    "base_rmse = np.sqrt(mean_squared_error(y_val, base_preds))\n",
    "print(f'Baseline RF RMSE: {base_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bb1dbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 1033.29\n"
     ]
    }
   ],
   "source": [
    "# 29. Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_preds = gbr.predict(X_val)\n",
    "gbr_rmse = np.sqrt(mean_squared_error(y_val, gbr_preds))\n",
    "print(f'Gradient Boosting RMSE: {gbr_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "83b633f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost RMSE: 1297.63\n"
     ]
    }
   ],
   "source": [
    "# 30. AdaBoost\n",
    "adb = AdaBoostRegressor(random_state=42)\n",
    "adb.fit(X_train, y_train)\n",
    "adb_preds = adb.predict(X_val)\n",
    "adb_rmse = np.sqrt(mean_squared_error(y_val, adb_preds))\n",
    "print(f'AdaBoost RMSE: {adb_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13372730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor RMSE: 1120.96\n"
     ]
    }
   ],
   "source": [
    "# 31. KNN Regressor\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_val)\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_val, knn_preds))\n",
    "print(f'KNN Regressor RMSE: {knn_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "89113ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RMSE: 1569.34\n"
     ]
    }
   ],
   "source": [
    "# 32. Support Vector Regressor\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "svr_preds = svr.predict(X_val)\n",
    "svr_rmse = np.sqrt(mean_squared_error(y_val, svr_preds))\n",
    "print(f'SVR RMSE: {svr_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "77f365ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 1121.04\n"
     ]
    }
   ],
   "source": [
    "# 33. XGBoost\n",
    "xgb = XGBRegressor(random_state=42, verbosity=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_preds = xgb.predict(X_val)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_val, xgb_preds))\n",
    "print(f'XGBoost RMSE: {xgb_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178ff84",
   "metadata": {},
   "source": [
    "### Based on the observation above Random forest and Gradient Boosing perform better than resr of the model so i'll take these 2 as refrence and work on hyper paramter tuning and cehck the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33a50041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Random Forest Validation RMSE: 1020.94\n"
     ]
    }
   ],
   "source": [
    "# 34. Hyperparameter tuning for Random Forest\n",
    "grid_params = {'n_estimators': [300,400], 'max_depth': [6,8], \n",
    "               'min_samples_split': [10,12], 'min_samples_leaf': [2,4]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "grid = GridSearchCV(rf, grid_params, cv=3, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "val_preds = grid.predict(X_val)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "print(f'Random Forest Validation RMSE: {val_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2335efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Gradient Boosting Validation RMSE: 1068.45\n"
     ]
    }
   ],
   "source": [
    "# 35. Hyperparameter tuning Gradient Boosting\n",
    "grid_params = {\n",
    "    'n_estimators': [300, 400], 'max_depth': [6, 8],'min_samples_split': [10, 12],\n",
    "    'min_samples_leaf': [2, 4],'learning_rate': [0.05, 0.1]}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(gbr,grid_params,cv=3,scoring='neg_root_mean_squared_error',verbose=1,n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "val_preds = grid.predict(X_val)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "print(f'Gradient Boosting Validation RMSE: {val_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f786676",
   "metadata": {},
   "source": [
    "# After submission I tried with hyperparamter tuning and got best stable result with cross validation 3 with grid_param combination Random Forest gives best RMSE which is 1020.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e2cdf",
   "metadata": {},
   "source": [
    "# Final Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e721c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    }
   ],
   "source": [
    "# 36. Final selection Random Forest\n",
    "grid_params = {'n_estimators': [400], 'max_depth': [6], \n",
    "               'min_samples_split': [10], 'min_samples_leaf': [2]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "grid = GridSearchCV(rf, grid_params, cv=3, scoring='neg_root_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf_final = RandomForestRegressor(**grid.best_params_, random_state=42, n_jobs=-1)\n",
    "rf_final.fit(X_scaled, y)\n",
    "final_preds = rf_final.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd11e0",
   "metadata": {},
   "source": [
    "# 9 : Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f9db0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37. Final submission\n",
    "submission = pd.DataFrame({\n",
    "    'Item_Identifier': test['Item_Identifier'].values,\n",
    "    'Outlet_Identifier': test['Outlet_Identifier'].values,\n",
    "    'Item_Outlet_Sales': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
